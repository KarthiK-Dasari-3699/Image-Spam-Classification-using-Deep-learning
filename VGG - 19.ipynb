{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7f0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import image, pyplot\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, f1_score, recall_score,classification_report,roc_curve, auc \n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from PIL import Image,ImageFile\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a82844",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultPath = 'C:/Users/HP/Downloads/Results/CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e14e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Reading  NaturalImages\n",
      ">>>Reading  SpamImages\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/HP/Downloads/Image_Hunter_dataset/\"\n",
    "spamData=[]\n",
    "label=[]\n",
    "hashList=[]\n",
    "count=-1\n",
    "for folder in os.listdir(DATA_PATH):\n",
    "    print(\">>>Reading \",folder)\n",
    "    count+=1\n",
    "    \n",
    "    for file in os.listdir(DATA_PATH+folder):\n",
    "        if(str(file).endswith('.jpg') or str(file).endswith('.JPG') or str(file).endswith('.jpeg') or str(file).endswith('.JPEG')):\n",
    "            img = image.imread(DATA_PATH+folder+'/'+file)\n",
    "            hsh = hash(tuple(np.array(img).flatten()))\n",
    "            if(hsh not in hashList):\n",
    "                spamData.append(resize(img, (156, 156, 3)))\n",
    "                hashList.append(hsh)\n",
    "                label.append(count)\n",
    "spamData=np.array(spamData)\n",
    "label=np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e0bd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SPAM 810\n",
      "Number of HAM 895\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of SPAM\",len(label[label==0]))\n",
    "print(\"Number of HAM\",len(label[label==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed9a188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam data shape :  (1705, 156, 156, 3)  Label shape :  (1705,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Spam data shape : \",spamData.shape,\" Label shape : \",label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68206502",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valid_Percentage = 0.3\n",
    "x_train,x_test,y_train,y_test = train_test_split(spamData,label,test_size = test_valid_Percentage,random_state=42, stratify=label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494f2358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (1193, 156, 156, 3)  y_train shape :  (1193,)\n",
      "x_test shape :  (512, 156, 156, 3)  y_test shape :  (512,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape : \",x_train.shape,\" y_train shape : \",y_train.shape)\n",
    "print(\"x_test shape : \",x_test.shape,\" y_test shape : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abcffa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train SPAM 567\n",
      "Number of train HAM 626\n",
      "Number of test SPAM 243\n",
      "Number of test HAM 269\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train SPAM\",len(y_train[y_train==0]))\n",
    "print(\"Number of train HAM\",len(y_train[y_train==1]))\n",
    "\n",
    "print(\"Number of test SPAM\",len(y_test[y_test==0]))\n",
    "print(\"Number of test HAM\",len(y_test[y_test==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d3cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_oh shape :  (1193, 2)  y_test_oh shape :  (512, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train_oh = to_categorical(y_train)\n",
    "y_test_oh = to_categorical(y_test)\n",
    "\n",
    "print(\"y_train_oh shape : \",y_train_oh.shape,\" y_test_oh shape : \",y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92257ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4 False\n",
      "block1_conv1 False\n",
      "block1_conv2 False\n",
      "block1_pool False\n",
      "block2_conv1 False\n",
      "block2_conv2 False\n",
      "block2_pool False\n",
      "block3_conv1 False\n",
      "block3_conv2 False\n",
      "block3_conv3 False\n",
      "block3_conv4 False\n",
      "block3_pool False\n",
      "block4_conv1 False\n",
      "block4_conv2 False\n",
      "block4_conv3 False\n",
      "block4_conv4 False\n",
      "block4_pool True\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_conv3 True\n",
      "block5_conv4 True\n",
      "block5_pool True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing Exception Network as Base Model for Transfer Learning\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "\n",
    "base_model_vgg = VGG19(input_shape=(156, 156,3), weights='imagenet', include_top=False,classes= 2)\n",
    "\n",
    "for layer in base_model_vgg.layers[:16]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model_vgg.layers[17:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "for layer in base_model_vgg.layers:\n",
    "    print(layer.name , layer.trainable)\n",
    "len(base_model_vgg.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf716857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 4, 4, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1048704   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,073,217\n",
      "Trainable params: 10,488,065\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NO_OF_EPOCHS=10\n",
    "BATCH_SIZE=64\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model_vgg)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f9ade8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9264 - accuracy: 0.5507WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 145s 7s/step - loss: 0.9264 - accuracy: 0.5507 - val_loss: 0.5476 - val_accuracy: 0.6523 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9455WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 146s 8s/step - loss: 0.1914 - accuracy: 0.9455 - val_loss: 0.0875 - val_accuracy: 0.9883 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9782WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 148s 8s/step - loss: 0.0976 - accuracy: 0.9782 - val_loss: 0.0679 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 143s 8s/step - loss: 0.0655 - accuracy: 0.9832 - val_loss: 0.0581 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9866WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 142s 8s/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.5905 - val_accuracy: 0.9199 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 143s 8s/step - loss: 0.1744 - accuracy: 0.9749 - val_loss: 0.2590 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9866WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 147s 8s/step - loss: 0.0823 - accuracy: 0.9866 - val_loss: 0.1023 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9916WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 142s 8s/step - loss: 0.0435 - accuracy: 0.9916 - val_loss: 0.1062 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 142s 8s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.1205 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 4.6340e-04 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 142s 8s/step - loss: 4.6340e-04 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9883 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245d36bb6a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = callbacks.ModelCheckpoint(filepath=resultPath+\"/checkpoint-{epoch:04d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger(resultPath+'/result_logger.csv',separator=',', append=False)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.2, patience=2, min_lr=0.001)\n",
    "model.fit(x_train,y_train,epochs= 10,verbose=1,batch_size= 64,validation_data=(x_test,y_test),callbacks=[checkpointer,csv_logger,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fbdda10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 36s 2s/step\n"
     ]
    }
   ],
   "source": [
    "prediction_prob1 = model.predict(x_test,verbose=1)\n",
    "y_pred=np.round(prediction_prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d3e1aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98828125\n",
      "0.9888475836431226\n",
      "0.9888475836431226\n",
      "0.9888475836431226\n",
      "[[240   3]\n",
      " [  3 266]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       243\n",
      "           1       0.99      0.99      0.99       269\n",
      "\n",
      "    accuracy                           0.99       512\n",
      "   macro avg       0.99      0.99      0.99       512\n",
      "weighted avg       0.99      0.99      0.99       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred,average='binary'))\n",
    "print(recall_score(y_test,y_pred,average='binary'))\n",
    "print(f1_score(y_test,y_pred,average='binary'))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb262265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e6f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daefa61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
