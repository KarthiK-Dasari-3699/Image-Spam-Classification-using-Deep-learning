{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7f0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import image, pyplot\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, f1_score, recall_score,classification_report,roc_curve, auc \n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from PIL import Image,ImageFile\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a82844",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultPath = 'C:/Users/HP/Downloads/Results/CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e14e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Reading  NaturalImages\n",
      ">>>Reading  SpamImages\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/HP/Downloads/Image_Hunter_dataset/\"\n",
    "spamData=[]\n",
    "label=[]\n",
    "hashList=[]\n",
    "count=-1\n",
    "for folder in os.listdir(DATA_PATH):\n",
    "    print(\">>>Reading \",folder)\n",
    "    count+=1\n",
    "    \n",
    "    for file in os.listdir(DATA_PATH+folder):\n",
    "        if(str(file).endswith('.jpg') or str(file).endswith('.JPG') or str(file).endswith('.jpeg') or str(file).endswith('.JPEG')):\n",
    "            img = image.imread(DATA_PATH+folder+'/'+file)\n",
    "            hsh = hash(tuple(np.array(img).flatten()))\n",
    "            if(hsh not in hashList):\n",
    "                spamData.append(resize(img, (156, 156, 3)))\n",
    "                hashList.append(hsh)\n",
    "                label.append(count)\n",
    "spamData=np.array(spamData)\n",
    "label=np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e0bd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SPAM 810\n",
      "Number of HAM 895\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of SPAM\",len(label[label==0]))\n",
    "print(\"Number of HAM\",len(label[label==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed9a188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam data shape :  (1705, 156, 156, 3)  Label shape :  (1705,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Spam data shape : \",spamData.shape,\" Label shape : \",label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68206502",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valid_Percentage = 0.3\n",
    "x_train,x_test,y_train,y_test = train_test_split(spamData,label,test_size = test_valid_Percentage,random_state=42, stratify=label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494f2358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (1193, 156, 156, 3)  y_train shape :  (1193,)\n",
      "x_test shape :  (512, 156, 156, 3)  y_test shape :  (512,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape : \",x_train.shape,\" y_train shape : \",y_train.shape)\n",
    "print(\"x_test shape : \",x_test.shape,\" y_test shape : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abcffa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train SPAM 567\n",
      "Number of train HAM 626\n",
      "Number of test SPAM 243\n",
      "Number of test HAM 269\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train SPAM\",len(y_train[y_train==0]))\n",
    "print(\"Number of train HAM\",len(y_train[y_train==1]))\n",
    "\n",
    "print(\"Number of test SPAM\",len(y_test[y_test==0]))\n",
    "print(\"Number of test HAM\",len(y_test[y_test==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d3cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_oh shape :  (1193, 2)  y_test_oh shape :  (512, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train_oh = to_categorical(y_train)\n",
    "y_test_oh = to_categorical(y_test)\n",
    "\n",
    "print(\"y_train_oh shape : \",y_train_oh.shape,\" y_test_oh shape : \",y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f92257ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_10 False\n",
      "conv1_pad False\n",
      "conv1_conv False\n",
      "conv1_bn False\n",
      "conv1_relu False\n",
      "pool1_pad False\n",
      "pool1_pool False\n",
      "conv2_block1_1_conv False\n",
      "conv2_block1_1_bn False\n",
      "conv2_block1_1_relu False\n",
      "conv2_block1_2_conv False\n",
      "conv2_block1_2_bn False\n",
      "conv2_block1_2_relu False\n",
      "conv2_block1_0_conv False\n",
      "conv2_block1_3_conv False\n",
      "conv2_block1_0_bn False\n",
      "conv2_block1_3_bn False\n",
      "conv2_block1_add False\n",
      "conv2_block1_out False\n",
      "conv2_block2_1_conv False\n",
      "conv2_block2_1_bn False\n",
      "conv2_block2_1_relu False\n",
      "conv2_block2_2_conv False\n",
      "conv2_block2_2_bn False\n",
      "conv2_block2_2_relu False\n",
      "conv2_block2_3_conv False\n",
      "conv2_block2_3_bn False\n",
      "conv2_block2_add False\n",
      "conv2_block2_out False\n",
      "conv2_block3_1_conv False\n",
      "conv2_block3_1_bn False\n",
      "conv2_block3_1_relu False\n",
      "conv2_block3_2_conv False\n",
      "conv2_block3_2_bn False\n",
      "conv2_block3_2_relu False\n",
      "conv2_block3_3_conv False\n",
      "conv2_block3_3_bn False\n",
      "conv2_block3_add False\n",
      "conv2_block3_out False\n",
      "conv3_block1_1_conv False\n",
      "conv3_block1_1_bn False\n",
      "conv3_block1_1_relu False\n",
      "conv3_block1_2_conv False\n",
      "conv3_block1_2_bn False\n",
      "conv3_block1_2_relu False\n",
      "conv3_block1_0_conv False\n",
      "conv3_block1_3_conv False\n",
      "conv3_block1_0_bn False\n",
      "conv3_block1_3_bn False\n",
      "conv3_block1_add False\n",
      "conv3_block1_out False\n",
      "conv3_block2_1_conv False\n",
      "conv3_block2_1_bn False\n",
      "conv3_block2_1_relu False\n",
      "conv3_block2_2_conv False\n",
      "conv3_block2_2_bn False\n",
      "conv3_block2_2_relu False\n",
      "conv3_block2_3_conv False\n",
      "conv3_block2_3_bn False\n",
      "conv3_block2_add False\n",
      "conv3_block2_out False\n",
      "conv3_block3_1_conv False\n",
      "conv3_block3_1_bn False\n",
      "conv3_block3_1_relu False\n",
      "conv3_block3_2_conv False\n",
      "conv3_block3_2_bn False\n",
      "conv3_block3_2_relu False\n",
      "conv3_block3_3_conv False\n",
      "conv3_block3_3_bn False\n",
      "conv3_block3_add False\n",
      "conv3_block3_out False\n",
      "conv3_block4_1_conv False\n",
      "conv3_block4_1_bn False\n",
      "conv3_block4_1_relu False\n",
      "conv3_block4_2_conv False\n",
      "conv3_block4_2_bn False\n",
      "conv3_block4_2_relu False\n",
      "conv3_block4_3_conv False\n",
      "conv3_block4_3_bn False\n",
      "conv3_block4_add False\n",
      "conv3_block4_out False\n",
      "conv4_block1_1_conv False\n",
      "conv4_block1_1_bn False\n",
      "conv4_block1_1_relu False\n",
      "conv4_block1_2_conv False\n",
      "conv4_block1_2_bn False\n",
      "conv4_block1_2_relu False\n",
      "conv4_block1_0_conv False\n",
      "conv4_block1_3_conv False\n",
      "conv4_block1_0_bn False\n",
      "conv4_block1_3_bn False\n",
      "conv4_block1_add False\n",
      "conv4_block1_out False\n",
      "conv4_block2_1_conv False\n",
      "conv4_block2_1_bn False\n",
      "conv4_block2_1_relu False\n",
      "conv4_block2_2_conv False\n",
      "conv4_block2_2_bn False\n",
      "conv4_block2_2_relu False\n",
      "conv4_block2_3_conv False\n",
      "conv4_block2_3_bn False\n",
      "conv4_block2_add False\n",
      "conv4_block2_out False\n",
      "conv4_block3_1_conv False\n",
      "conv4_block3_1_bn False\n",
      "conv4_block3_1_relu False\n",
      "conv4_block3_2_conv False\n",
      "conv4_block3_2_bn False\n",
      "conv4_block3_2_relu False\n",
      "conv4_block3_3_conv False\n",
      "conv4_block3_3_bn False\n",
      "conv4_block3_add False\n",
      "conv4_block3_out False\n",
      "conv4_block4_1_conv False\n",
      "conv4_block4_1_bn False\n",
      "conv4_block4_1_relu False\n",
      "conv4_block4_2_conv False\n",
      "conv4_block4_2_bn False\n",
      "conv4_block4_2_relu False\n",
      "conv4_block4_3_conv False\n",
      "conv4_block4_3_bn False\n",
      "conv4_block4_add False\n",
      "conv4_block4_out False\n",
      "conv4_block5_1_conv False\n",
      "conv4_block5_1_bn False\n",
      "conv4_block5_1_relu False\n",
      "conv4_block5_2_conv False\n",
      "conv4_block5_2_bn False\n",
      "conv4_block5_2_relu False\n",
      "conv4_block5_3_conv False\n",
      "conv4_block5_3_bn False\n",
      "conv4_block5_add False\n",
      "conv4_block5_out False\n",
      "conv4_block6_1_conv False\n",
      "conv4_block6_1_bn False\n",
      "conv4_block6_1_relu False\n",
      "conv4_block6_2_conv False\n",
      "conv4_block6_2_bn False\n",
      "conv4_block6_2_relu False\n",
      "conv4_block6_3_conv False\n",
      "conv4_block6_3_bn False\n",
      "conv4_block6_add False\n",
      "conv4_block6_out False\n",
      "conv5_block1_1_conv True\n",
      "conv5_block1_1_bn False\n",
      "conv5_block1_1_relu False\n",
      "conv5_block1_2_conv False\n",
      "conv5_block1_2_bn False\n",
      "conv5_block1_2_relu False\n",
      "conv5_block1_0_conv False\n",
      "conv5_block1_3_conv False\n",
      "conv5_block1_0_bn False\n",
      "conv5_block1_3_bn False\n",
      "conv5_block1_add False\n",
      "conv5_block1_out False\n",
      "conv5_block2_1_conv False\n",
      "conv5_block2_1_bn False\n",
      "conv5_block2_1_relu False\n",
      "conv5_block2_2_conv False\n",
      "conv5_block2_2_bn False\n",
      "conv5_block2_2_relu False\n",
      "conv5_block2_3_conv False\n",
      "conv5_block2_3_bn False\n",
      "conv5_block2_add False\n",
      "conv5_block2_out False\n",
      "conv5_block3_1_conv False\n",
      "conv5_block3_1_bn False\n",
      "conv5_block3_1_relu False\n",
      "conv5_block3_2_conv False\n",
      "conv5_block3_2_bn False\n",
      "conv5_block3_2_relu False\n",
      "conv5_block3_3_conv False\n",
      "conv5_block3_3_bn False\n",
      "conv5_block3_add False\n",
      "conv5_block3_out False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing Exception Network as Base Model for Transfer Learning\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "base_model_res = ResNet50(input_shape=(156, 156,3), weights='imagenet', include_top=False,classes= 2)\n",
    "\n",
    "for layer in base_model_res.layers[:143]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model_res.layers[144:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in base_model_res.layers:\n",
    "    print(layer.name , layer.trainable)\n",
    "len(base_model_res.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf716857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 5, 5, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 51200)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               6553728   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,141,569\n",
      "Trainable params: 7,078,657\n",
      "Non-trainable params: 23,062,912\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NO_OF_EPOCHS=10\n",
    "BATCH_SIZE=128\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model_res)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01f9ade8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0371 - accuracy: 0.5281WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 74s 4s/step - loss: 1.0371 - accuracy: 0.5281 - val_loss: 0.6961 - val_accuracy: 0.5293 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6025 - accuracy: 0.7008WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 72s 4s/step - loss: 0.6025 - accuracy: 0.7008 - val_loss: 0.3940 - val_accuracy: 0.9238 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.8625WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 96s 5s/step - loss: 0.3929 - accuracy: 0.8625 - val_loss: 0.2240 - val_accuracy: 0.9082 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8097WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 72s 4s/step - loss: 0.4041 - accuracy: 0.8097 - val_loss: 0.2413 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.9128WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 71s 4s/step - loss: 0.2534 - accuracy: 0.9128 - val_loss: 0.2982 - val_accuracy: 0.8789 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.9313WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 71s 4s/step - loss: 0.2073 - accuracy: 0.9313 - val_loss: 0.3070 - val_accuracy: 0.8711 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.9355WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 75s 4s/step - loss: 0.2008 - accuracy: 0.9355 - val_loss: 0.1421 - val_accuracy: 0.9629 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9640WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 71s 4s/step - loss: 0.1284 - accuracy: 0.9640 - val_loss: 0.1182 - val_accuracy: 0.9609 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9656WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 71s 4s/step - loss: 0.1131 - accuracy: 0.9656 - val_loss: 0.1213 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9145WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 73s 4s/step - loss: 0.2078 - accuracy: 0.9145 - val_loss: 0.2650 - val_accuracy: 0.8711 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24580ac16a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = callbacks.ModelCheckpoint(filepath=resultPath+\"/checkpoint-{epoch:04d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger(resultPath+'/result_logger.csv',separator=',', append=False)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.2, patience=2, min_lr=0.001)\n",
    "model.fit(x_train,y_train,epochs= 10,verbose=1,batch_size= 64,validation_data=(x_test,y_test),callbacks=[checkpointer,csv_logger,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fbdda10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 18s 1s/step\n"
     ]
    }
   ],
   "source": [
    "prediction_prob1 = model.predict(x_test,verbose=1)\n",
    "y_pred=np.round(prediction_prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d3e1aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87109375\n",
      "0.8029850746268656\n",
      "1.0\n",
      "0.890728476821192\n",
      "[[177  66]\n",
      " [  0 269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84       243\n",
      "           1       0.80      1.00      0.89       269\n",
      "\n",
      "    accuracy                           0.87       512\n",
      "   macro avg       0.90      0.86      0.87       512\n",
      "weighted avg       0.90      0.87      0.87       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred,average='binary'))\n",
    "print(recall_score(y_test,y_pred,average='binary'))\n",
    "print(f1_score(y_test,y_pred,average='binary'))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb262265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e6f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daefa61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
