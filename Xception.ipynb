{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb7f0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import image, pyplot\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, f1_score, recall_score,classification_report,roc_curve, auc \n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from PIL import Image,ImageFile\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20a82844",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultPath = 'C:/Users/HP/Downloads/Results/CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e14e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Reading  NaturalImages\n",
      ">>>Reading  SpamImages\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/HP/Downloads/Image_Hunter_dataset/\"\n",
    "spamData=[]\n",
    "label=[]\n",
    "hashList=[]\n",
    "count=-1\n",
    "for folder in os.listdir(DATA_PATH):\n",
    "    print(\">>>Reading \",folder)\n",
    "    count+=1\n",
    "    \n",
    "    for file in os.listdir(DATA_PATH+folder):\n",
    "        if(str(file).endswith('.jpg') or str(file).endswith('.JPG') or str(file).endswith('.jpeg') or str(file).endswith('.JPEG')):\n",
    "            img = image.imread(DATA_PATH+folder+'/'+file)\n",
    "            hsh = hash(tuple(np.array(img).flatten()))\n",
    "            if(hsh not in hashList):\n",
    "                spamData.append(resize(img, (156, 156, 3)))\n",
    "                hashList.append(hsh)\n",
    "                label.append(count)\n",
    "spamData=np.array(spamData)\n",
    "label=np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e0bd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SPAM 810\n",
      "Number of HAM 895\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of SPAM\",len(label[label==0]))\n",
    "print(\"Number of HAM\",len(label[label==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed9a188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam data shape :  (1705, 156, 156, 3)  Label shape :  (1705,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Spam data shape : \",spamData.shape,\" Label shape : \",label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68206502",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valid_Percentage = 0.3\n",
    "x_train,x_test,y_train,y_test = train_test_split(spamData,label,test_size = test_valid_Percentage,random_state=42, stratify=label,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "494f2358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (1193, 156, 156, 3)  y_train shape :  (1193,)\n",
      "x_test shape :  (512, 156, 156, 3)  y_test shape :  (512,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape : \",x_train.shape,\" y_train shape : \",y_train.shape)\n",
    "print(\"x_test shape : \",x_test.shape,\" y_test shape : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcffa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train SPAM 567\n",
      "Number of train HAM 626\n",
      "Number of test SPAM 243\n",
      "Number of test HAM 269\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train SPAM\",len(y_train[y_train==0]))\n",
    "print(\"Number of train HAM\",len(y_train[y_train==1]))\n",
    "\n",
    "print(\"Number of test SPAM\",len(y_test[y_test==0]))\n",
    "print(\"Number of test HAM\",len(y_test[y_test==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d3cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_oh shape :  (1193, 2)  y_test_oh shape :  (512, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train_oh = to_categorical(y_train)\n",
    "y_test_oh = to_categorical(y_test)\n",
    "\n",
    "print(\"y_train_oh shape : \",y_train_oh.shape,\" y_test_oh shape : \",y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f92257ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_5 False\n",
      "block1_conv1 False\n",
      "block1_conv1_bn False\n",
      "block1_conv1_act False\n",
      "block1_conv2 False\n",
      "block1_conv2_bn False\n",
      "block1_conv2_act False\n",
      "block2_sepconv1 False\n",
      "block2_sepconv1_bn False\n",
      "block2_sepconv2_act False\n",
      "block2_sepconv2 False\n",
      "block2_sepconv2_bn False\n",
      "conv2d_16 False\n",
      "block2_pool False\n",
      "batch_normalization_16 False\n",
      "add_48 False\n",
      "block3_sepconv1_act False\n",
      "block3_sepconv1 False\n",
      "block3_sepconv1_bn False\n",
      "block3_sepconv2_act False\n",
      "block3_sepconv2 False\n",
      "block3_sepconv2_bn False\n",
      "conv2d_17 False\n",
      "block3_pool False\n",
      "batch_normalization_17 False\n",
      "add_49 False\n",
      "block4_sepconv1_act False\n",
      "block4_sepconv1 False\n",
      "block4_sepconv1_bn False\n",
      "block4_sepconv2_act False\n",
      "block4_sepconv2 False\n",
      "block4_sepconv2_bn False\n",
      "conv2d_18 False\n",
      "block4_pool False\n",
      "batch_normalization_18 False\n",
      "add_50 False\n",
      "block5_sepconv1_act False\n",
      "block5_sepconv1 False\n",
      "block5_sepconv1_bn False\n",
      "block5_sepconv2_act False\n",
      "block5_sepconv2 False\n",
      "block5_sepconv2_bn False\n",
      "block5_sepconv3_act False\n",
      "block5_sepconv3 False\n",
      "block5_sepconv3_bn False\n",
      "add_51 False\n",
      "block6_sepconv1_act False\n",
      "block6_sepconv1 False\n",
      "block6_sepconv1_bn False\n",
      "block6_sepconv2_act False\n",
      "block6_sepconv2 False\n",
      "block6_sepconv2_bn False\n",
      "block6_sepconv3_act False\n",
      "block6_sepconv3 False\n",
      "block6_sepconv3_bn False\n",
      "add_52 False\n",
      "block7_sepconv1_act False\n",
      "block7_sepconv1 False\n",
      "block7_sepconv1_bn False\n",
      "block7_sepconv2_act False\n",
      "block7_sepconv2 False\n",
      "block7_sepconv2_bn False\n",
      "block7_sepconv3_act False\n",
      "block7_sepconv3 False\n",
      "block7_sepconv3_bn False\n",
      "add_53 False\n",
      "block8_sepconv1_act False\n",
      "block8_sepconv1 False\n",
      "block8_sepconv1_bn False\n",
      "block8_sepconv2_act False\n",
      "block8_sepconv2 False\n",
      "block8_sepconv2_bn False\n",
      "block8_sepconv3_act False\n",
      "block8_sepconv3 False\n",
      "block8_sepconv3_bn False\n",
      "add_54 False\n",
      "block9_sepconv1_act False\n",
      "block9_sepconv1 False\n",
      "block9_sepconv1_bn False\n",
      "block9_sepconv2_act False\n",
      "block9_sepconv2 False\n",
      "block9_sepconv2_bn False\n",
      "block9_sepconv3_act False\n",
      "block9_sepconv3 False\n",
      "block9_sepconv3_bn False\n",
      "add_55 False\n",
      "block10_sepconv1_act False\n",
      "block10_sepconv1 False\n",
      "block10_sepconv1_bn False\n",
      "block10_sepconv2_act False\n",
      "block10_sepconv2 False\n",
      "block10_sepconv2_bn False\n",
      "block10_sepconv3_act False\n",
      "block10_sepconv3 False\n",
      "block10_sepconv3_bn False\n",
      "add_56 False\n",
      "block11_sepconv1_act False\n",
      "block11_sepconv1 False\n",
      "block11_sepconv1_bn False\n",
      "block11_sepconv2_act False\n",
      "block11_sepconv2 False\n",
      "block11_sepconv2_bn False\n",
      "block11_sepconv3_act False\n",
      "block11_sepconv3 False\n",
      "block11_sepconv3_bn False\n",
      "add_57 False\n",
      "block12_sepconv1_act False\n",
      "block12_sepconv1 False\n",
      "block12_sepconv1_bn False\n",
      "block12_sepconv2_act False\n",
      "block12_sepconv2 False\n",
      "block12_sepconv2_bn False\n",
      "block12_sepconv3_act False\n",
      "block12_sepconv3 False\n",
      "block12_sepconv3_bn False\n",
      "add_58 True\n",
      "block13_sepconv1_act True\n",
      "block13_sepconv1 True\n",
      "block13_sepconv1_bn True\n",
      "block13_sepconv2_act True\n",
      "block13_sepconv2 True\n",
      "block13_sepconv2_bn True\n",
      "conv2d_19 True\n",
      "block13_pool True\n",
      "batch_normalization_19 True\n",
      "add_59 True\n",
      "block14_sepconv1 True\n",
      "block14_sepconv1_bn True\n",
      "block14_sepconv1_act True\n",
      "block14_sepconv2 True\n",
      "block14_sepconv2_bn True\n",
      "block14_sepconv2_act True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing Exception Network as Base Model for Transfer Learning\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "base_model_xcp = Xception(include_top=False, weights='imagenet',\n",
    "            input_shape=(156, 156,3), classes= 2)\n",
    "for layer in base_model_xcp.layers[:115]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model_xcp.layers[116:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "for layer in base_model_xcp.layers:\n",
    "    print(layer.name , layer.trainable)\n",
    "len(base_model_xcp.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf716857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 51200)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               6553728   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,415,337\n",
      "Trainable params: 13,342,241\n",
      "Non-trainable params: 14,073,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NO_OF_EPOCHS=10\n",
    "BATCH_SIZE=64\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model_xcp)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01f9ade8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9346WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 116s 6s/step - loss: 0.2726 - accuracy: 0.9346 - val_loss: 0.8747 - val_accuracy: 0.9609 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9933WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 104s 6s/step - loss: 0.0797 - accuracy: 0.9933 - val_loss: 2.5075 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9933WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 105s 6s/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 0.8246 - val_accuracy: 0.9844 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9983WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 105s 6s/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 1.1295 - val_accuracy: 0.9336 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9992WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 105s 6s/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 0.8762 - val_accuracy: 0.9277 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9983WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 105s 6s/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.4074 - val_accuracy: 0.9844 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9983WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 104s 6s/step - loss: 0.0153 - accuracy: 0.9983 - val_loss: 0.1850 - val_accuracy: 0.9883 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9992WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 101s 5s/step - loss: 0.0172 - accuracy: 0.9992 - val_loss: 0.1200 - val_accuracy: 0.9824 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9975WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 105s 6s/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.1748 - val_accuracy: 0.9824 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9992WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "19/19 [==============================] - 105s 6s/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.2096 - val_accuracy: 0.9805 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4756a6e20>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = callbacks.ModelCheckpoint(filepath=resultPath+\"/checkpoint-{epoch:04d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger(resultPath+'/result_logger.csv',separator=',', append=False)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.2, patience=2, min_lr=0.001)\n",
    "model.fit(x_train,y_train,epochs= 10,verbose=1,batch_size= 64,validation_data=(x_test,y_test),callbacks=[checkpointer,csv_logger,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fbdda10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 32s 1s/step\n"
     ]
    }
   ],
   "source": [
    "prediction_prob1 = model.predict(x_test,verbose=1)\n",
    "y_pred=np.round(prediction_prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d3e1aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98046875\n",
      "0.9743589743589743\n",
      "0.9888475836431226\n",
      "0.9815498154981549\n",
      "[[236   7]\n",
      " [  3 266]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       243\n",
      "           1       0.97      0.99      0.98       269\n",
      "\n",
      "    accuracy                           0.98       512\n",
      "   macro avg       0.98      0.98      0.98       512\n",
      "weighted avg       0.98      0.98      0.98       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred,average='binary'))\n",
    "print(recall_score(y_test,y_pred,average='binary'))\n",
    "print(f1_score(y_test,y_pred,average='binary'))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb262265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e6f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daefa61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
